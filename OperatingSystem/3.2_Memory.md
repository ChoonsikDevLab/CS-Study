# 메모리 계층
먼저, 메모리의 계층은 다음과 같다.  

1. 레지스터 
2. 캐시
3. 주 기적장치
4. 보조 기억장치

![image](https://github.com/user-attachments/assets/c1ce110e-dbb9-4e44-88d0-c1598a898f0b)

출처 : https://computerscience.chemeketa.edu/cs160Reader/ComputerArchitecture/MemoryHeirarchy.html

# 캐시(cache)
데이터를 미리 복사해 놓은 임시 저장소  
빠른 장치와 느린 장치에서 속도 차이로 발생하는 병목 현상을 줄이기 위한 장치

## 캐시 히트와 캐시 미스
- 캐시 히트(cache hit)
	- 캐시 메모리가 예측하여 저장한 데이터가 CPU에 의해 실제 사용되는 경우
- 캐시 미스(cache miss)
	- 예측하여 저장했지만 틀린 예측으로 CPU가 메모리에서 직접 필요한 데이터를 가져와야 하는 경우

캐시 적중률(cache hit ratio) : 캐시가 히트되는 비율
> 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)

\*범용적으로 사용되는 컴퓨터의 캐시 적중률은 대략 85~95%

### 참조 지역성의 원리(locality of reference, principle of locality)
CPU가 메모리에 접근할 때 보이는 주된 경향을 말한다.

- 시간 지역성(temporal locality)
	- CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다. (예 : 변수)
- 공간 지역성(spatial locality)
	- CPU는 접근한 메모리 공간의 주변에 접근하려는 경향이 있다. (예 : 배열)

### 캐시 매핑(캐시 배치, 캐시 사상)
캐시가 히트되기 위해 매핑하는 방법

- 직접 매핑(directed mapping) : 가장 단순한 방법, 주기억장치의 특정 블록이 캐시의 특정 라인에만 매핑 
  → 메모리 주소의 일부를 사용하여 캐시 라인을 결정
	- 장점 : 구현 간단, 적은 비용 
	- 단점 : 같은 캐시 라인에 여러 메모리 블록이 매핑될 수 있기에 충돌 가능 → 캐시 적중률 하락
- 연관 매핑(associative mapping) : 주기억장치의 블록을 캐시 어느 라인에나 저장할 수 있는 방식
	- 장점 : 적중률 상승 가능, 충돌 가능성 하락
	- 단점 : 모든 캐시 라인을 검색해야 하기에 속도 저하 가능, 구현 복잡 및 비용 증가
- 집합 연관 매핑(set associative mapping) : 직접 매핑, 연관 매핑을 결합한 방식
	- 특징 : n-way 집합 연관 매핑에서 캐시를 여러 집합으로 나누고, 각 집합은 n개의 라인을 포함. 메모리 블록은 특정 집합 내 어느 라인에나 매핑 가능
	- 장점 : 직접 매핑보다 유연, 연관 매핑보다 검색 빠름
	- 단점 : 직접 매핑 보다 구현 복잡 및 연관 매핑보다 충돌 가능성 높음 (상대적)

![image](https://github.com/user-attachments/assets/aad1c10b-d7e9-4b8a-a6d5-5bf0d54ef7cd)

출처: https://commons.wikimedia.org/w/index.php?curid=851638

### cf. 브라우저 캐시
\*네트워크 파트를 참고
- 쿠키
- 로컬 스토리지
- 세션 스토리지

# 메모리 관리
## 메모리 구조
- 물리 주소(physical address)
	- 메모리 하드웨어에서 실제로 사용되는 주소
	- 메모리 관리 장치 MMU에 의해 계산됨
- 논리 주소(logical address)
	- CPU와 실행중인 프로그램이 사용하는 가상의 주소
	- 독립적인 0번지부터 시작하는 주소 공간을 가짐

- MMU(Memory Management Unit)
	- CPU와 메모리 사이 위치
	- CPU가 이해하는 논리 주소를 메모리가 이해하는 물리 주소로 변환
	- MMU를 기준으로 물리 주소와 논리 주소가 변환됨

## 스왑(swap)
물리적 메모리가 부족할 때 디스크 공간을 임시 메모리로 활용하는 메모리 관리 기술
이를 통해 시스템은 실제 물리적 메모리보다 더 큰 가상 메모리를 사용할 수 있다

- 스왑 영역(swap space)
	- 스왑을 위해 할당된 디스크의 특정 공간
	- 스왑 파티션, 스왑 파일 두 형태로 구현된다
- 스와핑(swapping)
	- 프로세스나 메모리 페이지를 주 기억장치와 보조 기억장치 사이에서 이동시키는 과정
	- 스왑 아웃(swap-out) : 메모리 영역 → 스왑 영역
	- 스왑 인(swap-in) : 스왑 영역 → 메모리 영역

## 스래싱(thrashing)
- 과도한 페이지 교체로 인해 실제 작업보다 페이징에 더 많은 시간을 사용하는 현상
- 메모리의 페이지 부재율(page fault)이 높아 CPU 이용률이 떨어지는 상태
- 시스템 성능 저하 주요 원인

#### 해결 방법
- 작업 세트(working set) : 프로세스가 자주 참조하는 페이지들을 메모리에 유지(미리 로드)
- PFF(Page Fault Frequency) : 페이지 부재율을 모니터링하여 프로세스에 할당된 메모리 양을 동적으로 조절


# 메모리 할당 방식

## 단편화(Fragmentation)

![image](https://github.com/user-attachments/assets/6095bf5a-fb62-4518-8bbd-b5397c81b38d)

### 내부 단편화(Internal Fragmentation)
- 프로세스에 할당된 메모리가 실제로 필요한 양(요청된 메모리 크기)보다 더 클 경우
- 메모리 할당 단위(ex. 페이지)가 프로세스의 실제 필요 크기와 정확히 일치하지 않을 경우 발생하여 메모리 일부가 사용되지 않고 낭비됨
- 예 : 4KB 페이지 시스템에서 프로세스가 3KB만 필요한 경우, 1KB는 낭비됨
### 외부 단편화(External Fragmentation)
- 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 현상
- 메모리 공간이 작은 조각으로 나뉘어 있어 총 여유 공간은 충분하지만 연속된 큰 블록을 할당할 수 없는 상황
- 예 : 50MB + 50MB = 100MB의 빈 공간이 있으나, 80MB 프로세스를 할당할 수 없을 때
### 압축(compaction)
- 메모리의 모든 내용을 한 군데로 몰고 가용 공간을 다른 한 군데로 몰아서 큰 블록을 만드는 것
- 외부 단편화 문제 해결 가능
- 비용이 크고(오버헤드 발생 가능), 압축이 항상 가능한 것만은 아님

## 연속 할당
- 프로세스가 메모리의 공간에 연속되게 할당하는 방식
- 외부 단편화가 발생할 수 있음

![image](https://github.com/user-attachments/assets/3c7f3e5d-f567-43a0-ba98-0f856926ed6e)

### 고정 분할 방식
- 메모리를 미리 나누어 관리하는 방식
**장점**
- 구현이 간단하고 오버헤드가 적음
- 메모리 관리가 수월할 수 있음
**단점**
- 융통성이 떨어짐
- 내부 단편화가 발생할 수 있음

### 가변 분할 방식
- 매 시점 프로그램의 크기에 따라 동적으로 메모리를 할당하는 방식
**장점**
- 프로세스를 한 덩어리로 처리하여 연속된 공간에 배치할 수 있음
- 내부 단편화가 발생하지 않음
**단점**
- 외부 단편화가 발생할 수 있음
- 빈 공간 관리가 어렵고, 메모리 관리가 복잡해짐

**분할 방식**
- 최초적합(First-fit)
	- 위쪽이나 아래쪽부터 시작하여 홀을 찾으면 바로 할당
	- 빠른 할당이 가능하나, 메모리 시작 부근에 자잘한 빈 공간들이 많아질 수 있음
- 최적적합(Best-fit)
	- 프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당
	- 메모리 사용에 최적화이나, 이를 관리하기 위한 추가 오버헤드 발생 가능
- 최악접합(Worst-fit)
	- 프로세스의 크기와 가장 많이 차이가 나는홀에 할당
	- 큰 공간을 유지하려고 하기에, 실제 메모리 사용 효율성이 떨어질 수 있음

## 불연속 할당(가상 메모리 기법)
메모리를 동일한 크기의 페이지로 나누어 프로그램마다 페이지 테이블을 두어 할당하는 방식

기존 연속 메모리 할당 + 스와핑은 두 가지 문제가 발생
- 적재와 삭제를 반복하며 프로세스 사이에 발생하는 외부 단편화
- 물리 메모리보다 큰 프로세스를 실행 불가
→ 이를 해결하기 위해 가상 메모리(Virtual memory) 방식이 도입

### 가상 주소 공간(virtual address space)
- 가상 메모리 기법으로 생성된 논리 주소 공간
- 이를 통해 프로세스는 실제 물리 메모리 크기에 구애받지 않고 더 큰 주소 공간을 사용할 수 있음

### 페이징(paging)

![image](https://github.com/user-attachments/assets/f30d4374-0e1b-406d-8f52-a17f8c81fd72)

- 프로세스의 논리 주소 공간을 **페이지(page)** 라는 일정 단위로 나누고, 물리 주소 공간을 동일한 크기의 **프레임(frame)** 단위로 나누어 페이지를 프레임에 할당하는 가상 메모리 관리 기법
- 프로세스를 구성하는 페이지는 물리 메모리 내에 불연속적으로 배치될 수 있음
- 외부 단편화가 발생하지 않으나, 페이지 테이블 관리에 따른 오버헤드 존재

- 페이징 기법에도 스와핑이 사용될 수 있음
	- 프로세스 전체가 아닌 페이지 단위로 스왑 인/아웃이 됨
	  페이징 시스템의 스왑 아웃은 페이지 아웃(page out), 스왑 인은 페이지 인(page in)
	- **프로세스를 실행하기 위해 전체 프로세스가 메모리에 적재할 필요가 없음을 시사**
	  → 논리 메모리의 크기가 실제 메모리보다 클 수 있으며, 물리 메모리보다 큰 크기의 프로세스도 실행 가능

#### 페이지 테이블
- 불연속적으로 배치된 페이지가 적재된 프레임의 위치를 매핑하는 테이블
- 페이지 테이블에 페이지 번호와 실제 적재된 프레임 번호가 대응

![image](https://github.com/user-attachments/assets/a7e27d31-bda7-453a-a968-0c9e9f5fec5f)

출처 : https://velog.io/@passion_man/운영체제-9.-페이징-메모리-관리

- 페이지 테이블을 구성하고 있는 각각의 행을 테이블 엔트리(PTE, Page Table Entry)라고 함
- PTE에 포함된 대표적인 정보
	- 페이지 번호, 프레임 번호, 유효 비트, 보호 비트, 참조 비트, 수정 비트
- 유효 비트(valid bit) : 해당 페이지에 접근이 가능한지 여부를 알려주는 항목
	- 현재 페이지가 메모리 또는 보조 기억장치에 적재되어 있는지를 알려줌
	- 메모리에 적재되어 있다면 1, 아닐 경우 0
- 만약 CPU가 메모리에 적재되지 않은 페이지, 유효 비트가 0인 페이지에 접근할 경우 **페이지 폴트(page fault)** 라는 예외(Exception)이 발생

CPU의 페이지 폴트 처리 과정
1. 기존 작업을 백업
2. 페이지 폴트 처리 루틴을 실행
	- 원하는 페이지를 메모리로 가져와 유효 비트를 1로 변경하는 작업
3. 페이지 폴트 처리 루틴 실행 후 메모리에 적재된 페이지를 실행

#### 페이지 폴트 종류
1. 메이저 페이지 폴트
	- 보조 기억장치에서 페이지를 읽어와야 하는 경우
	- 입출력 작업이 필요하기에 처리 시간이 추가로 필요
2. 마이너 페이지 폴트
	- 페이지가 이미 물리 메모리에 있으나, 페이지 테이블에 반영되지 않은 경우
	- 보조 기억장치 접근 없이 해결 가능하기에 상대적으로 빠름

#### 요구 페이징(Demand Paging)
- 프로세스 실행에 필요한 페이지만 메모리에 적재하는 방법
- 페이지 폴트 발생 시 필요한 페이지를 메모리에 로드
- 메모리 사용 효율성 증가, 입출력 오버헤드 감소

### 세그멘테이션(segmentation)
- 프로세스를 일정 크기의 페이지 단위가 아닌 가변적 크기인 **세그먼트(segment)** 단위로 분할하여 사용하는 가상 메모리 관리 기법
- 세그먼트 크기가 일정하지 않기 때문에 외부 단편화가 발생할 수 있음


## 페이지 교체 알고리즘
메모리가 가득 찼을 때 새로운 페이지를 적재하기 위해 어떤 페이지를 스왑 아웃 할 지 결정하는 방법

### FIFO(First-In First-Out)
- 가장 먼저 메모리에 적재된 페이지를 교체
- 구현이 간단하나, 성능이 좋지 않음
- 자주 사용되는 페이지가 교체될 수 있음

### 최적 알고리즘(OPT, Optimal)
- 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체
- 모든 페이지 교체 알고리즘 중 page-fault 발생이 가장 적음
- 프로세스가 앞으로 사용 할 페이지를 미리 알아야 함
- 이론적으로 최적이나, 미래 예측이 필요하기에 실제에 맞게 구현은 불가능에 가까움

### LRU(Least Recently Used)
- 가장 오랫동안 사용되지 않은 페이지를 교체
- 성능이 좋은 편
- 많은 운영체제에서 채택하는 알고리즘

### 기타 알고리즘
- LFU (Least Frequently Used): 사용 빈도(참조 횟수)가 가장 적은 페이지 교체
- MFU (Most Frequently Used): 참조 횟수가 가장 많은 페이지 교체
- NUR (Not Used Recently): LRU와 비슷한 알고리즘, 최근에 사용하지 않은 페이지 교체, 최근 사용 여부를 확인하기 위해 각 페이지마다 두 개의 비트 사용(참조 비트, 변형 비트)
- SCR (Second Chance Replacement): FIFO의 단점을 보완한 알고리즘. 자주 사용되는 페이지의 교체를 방지하기 위해 각 페이지마다 참조비트를 둚



# 면접 질문

<details>
<summary>
페이지 폴트가 발생하는 상황과 처리하는 과정을 설명해주세요.
</summary>
```
CPU의 페이지 폴트는 프로세스가 접근하려는 페이지가 현재 물리 메모리에 없을 때 발생합니다.
처리 과정은 다음과 같습니다.
1. CPU가 기존 작업을 백업하고
2. 페이지 폴트 처리 루틴을 실행합니다. 페이지 처리 루틴은 메모리로 원하는 페이지를 로드하여 유효 비트를 1로 변경해 주는 작업입니다.
3. 이렇게 페이지 폴트를 처리하면 CPU는 해당 페이지에 접근할 수 있게 됩니다.
```
</details>

<details>
<summary>
메모리가 부족하면 발생할 수 있는 현상을 설명해주세요.
</summary>
```
메모리가 부족할 경우 운영체제는 부족한 메모리를 보완하기 위해 보조 기억장치(디스크)에 메모리 페이지를 저장하고, 필요할 때 다시 불러오는 과정인 스와핑을 이용합니다. 이 작업이 과도하게 이루어지면 스래싱이라는 현상을 불러올 수 있으며, 시스템이 지속적으로 디스크 I/O에만 몰두하게 되어 실제 작업 처리가 과도하게 지연될 수 있습니다.
```
</details>

<details>
<summary>
가상 메모리(Virtual Memory)란 무엇이며 장점은 어떠한 것이 있나요?
</summary>
```
물리적 메모리의 한계를 극복하기 위해 고안된 메모리 관리 방법 입니다. 
프로세스의 논리적 주소 공간과 물리적 주소 공간을 분리하며, 실제 물리 메모리보다 큰 메모리 공간을 사용할 수 있게 해줍니다.
```
</details>

<details>
<summary>
페이징과 세그멘테이션의 차이점을 설명해주세요.
</summary>
```
페이징은 물리 메모리를 고정 크기의 프레임으로 나누고, 논리 메모리를 같은 크기의 페이지로 나눕니다. 내부 단편화가 발생할 수 있으나, 외부 단편화가 발생하지 않습니다.
세그멘테이션은 논리적 단위(세그먼트)로 메모리 공간을 나누는데 각 세그먼트의 크기는 가변적으로 나누기 때문에 내부 단편화가 발생하지 않지만, 외부 단편화가 발생할 수 있습니다.
```
</details>

<details>
<summary>
내부 단편화와 외부 단편화의 차이점은 무엇인가요?
</summary>
```
내부 단편화는 할당된 메모리 공간이 요청된 메모리 공간보다 클 경우를 말하며,
외부 단편화는 할당화 해제를 반복하며 작은 메모리 공간이 생겨 어떠한 프로세스를 로드할 수 있는 메모리 공간이 있으나 연속적으로 할당할 수 없을 경우를 말합니다.
```
</details>

<details>
<summary>
스래싱이란 무엇이며 어떻게 방지할 수 있나요?
</summary>
```
스래싱은 과도한 페이지 교체로 인해 실제 작업보다 페이징에 더 많은 시간을 소모하는 현상입니다.
방지 방법은 작업 세트 모델 사용, 페이지 폴트 빈도 조절, 적절한 수의 프로세스 만 실행하는 방법이 있습니다.
- 작업 세트 모델 : 프로세스가 일정 시간동안 자주 사용하는 페이지 집한을 유지
- 페이지 폴트 빈도 조절 : 페이지 폴트 비율을 모니터링하고, 임계값을 설정
- 적절한 수의 프로세스만 실행 : 다중 프로그래밍의 정도를 제한
```
</details>

<details>
<summary>
캐시 미스란 무엇이며, 캐시 미스가 프로그램의 성능에 어떤 영향을 미치나요?
</summary>
```
캐시 미스란 캐시에 있을 것이라 기대했던 데이터가 캐시에 존재하지 않을 경우를 말합니다.
캐시 미스가 발생하면 캐시를 활용하지 못하고, 메모리와 같은 실제 데이터가 위치한 곳까지 접근해야 하기 때문에 처리 시간이 발생할 수 있습니다.
```
</details>
